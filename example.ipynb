{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "os.environ['HF_HOME'] = '/root/autodl-tmp/huggingface'\n",
    "os.environ['MODELSCOPE_CACHE'] = '/root/autodl-tmp/modelscope/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = False\n",
    "if init:\n",
    "    !pip install huggingface_hub peft opencv-python einops gradio spaces GPUtil\n",
    "    !conda install -c conda-forge gxx=11 gcc=11 -y\n",
    "    %cd /root/autodl-tmp/nunchaku\n",
    "    !git submodule init\n",
    "    !git submodule update\n",
    "    !VERBOSE=1 pip install -e . -v\n",
    "    !cat /root/autodl-tmp/nunchaku/build/temp*/compile_commands.json  # 如果存在\n",
    "\n",
    "%cd /root/autodl-fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "\n",
    "qmodel_path = \"mit-han-lab/svdquant-models/svdq-int4-flux.1-dev.safetensors\"\n",
    "\n",
    "if not os.path.exists(qmodel_path):\n",
    "    hf_repo_id = os.path.dirname(qmodel_path)\n",
    "    filename = os.path.basename(qmodel_path)\n",
    "    qmodel_path = hf_hub_download(repo_id=hf_repo_id, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from nunchaku.pipelines import flux as nunchaku_flux\n",
    "\n",
    "pipeline = nunchaku_flux.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    qmodel_path=\"mit-han-lab/svdquant-models/svdq-int4-flux.1-dev.safetensors\",  # download from Huggingface\n",
    "    qencoder_path=\"mit-han-lab/svdquant-models/svdq-w4a16-t5.pt\",\n",
    ").to(\"cuda\")\n",
    "image = pipeline(\n",
    "    \"A cat holding a sign that says hello world\",\n",
    "    num_inference_steps=28,\n",
    "    guidance_scale=3.5,\n",
    ").images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
