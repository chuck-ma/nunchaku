{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88ea33-4483-40a5-af5f-fb8f06710f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3bc7e9-cf93-4217-8e7e-a432288b94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "os.environ['HF_HOME'] = '/root/autodl-tmp/huggingface'\n",
    "os.environ['MODELSCOPE_CACHE'] = '/root/autodl-tmp/modelscope/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff5be43-645a-4aeb-b341-1d4c3ff02160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!du -sh /root/autodl-tmp/deepcompressor/\n",
    "# !du -sh /root/autodl-tmp/huggingface/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d757cc4-093c-4e79-ba82-1607866a057b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bf1182-ce29-4d40-b4d1-f7ef6ce3b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r /root/autodl-fs/models--jasperai--Flux.1-dev-Controlnet-Depth/ /root/autodl-tmp/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd11817-515d-4a10-939e-b017e1f27112",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/autodl-tmp/.Trash-0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba77588-336b-42da-bdab-cd2bfa9f527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from diffusers import FluxTransformer2DModel\n",
    "import torch\n",
    "\n",
    "\n",
    "def load_flux_model(\n",
    "    model_path: str,\n",
    "    load_from_file: bool = True,\n",
    "    use_4bit: bool = False,\n",
    "    dtype: torch.dtype = torch.bfloat16,\n",
    ") -> FluxTransformer2DModel:\n",
    "    \"\"\"\n",
    "    加载FLUX模型，支持从单文件或预训练目录加载\n",
    "\n",
    "    参数:\n",
    "        model_path: 模型路径，可以是safetensors文件路径或预训练模型目录\n",
    "        load_from_file: 是否从单个文件加载\n",
    "        use_4bit: 是否使用4bit量化\n",
    "        dtype: 模型计算精度\n",
    "    \"\"\"\n",
    "    if use_4bit:\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=dtype\n",
    "        )\n",
    "    else:\n",
    "        quantization_config = None\n",
    "\n",
    "    if load_from_file:\n",
    "        model = FluxTransformer2DModel.from_single_file(\n",
    "            model_path, quantization_config=quantization_config, torch_dtype=dtype\n",
    "        )\n",
    "    else:\n",
    "        model = FluxTransformer2DModel.from_pretrained(\n",
    "            model_path, quantization_config=quantization_config, torch_dtype=dtype\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "ckpt_repo = \"Kijai/flux-fp8\"\n",
    "ckpt_filename = \"flux1-dev-fp8-e4m3fn.safetensors\"\n",
    "\n",
    "ckpt_path = hf_hub_download(ckpt_repo, filename=ckpt_filename)\n",
    "\n",
    "model = load_flux_model(ckpt_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620b3273-0488-420b-b496-724d61a85b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90139325-57e2-4773-b304-082f54fefce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-12 21:49:33.233] [info] Initializing QuantizedFluxModel\n",
      "[2024-11-12 21:49:33.420] [info] Loading weights from /root/autodl-tmp/huggingface/hub/models--mit-han-lab--svdquant-models/snapshots/d2a46e82a378ec70e3329a2219ac4331a444a999/svdq-int4-flux.1-dev.safetensors\n",
      "[2024-11-12 21:49:35.124] [info] Done.\n"
     ]
    }
   ],
   "source": [
    "from nunchaku.models.flux  import inject_transformer, load_quantized_model\n",
    "\n",
    "qmodel_path = \"mit-han-lab/svdquant-models/svdq-int4-flux.1-dev.safetensors\"\n",
    "\n",
    "if not os.path.exists(qmodel_path):\n",
    "    hf_repo_id = os.path.dirname(qmodel_path)\n",
    "    filename = os.path.basename(qmodel_path)\n",
    "    qmodel_path = hf_hub_download(repo_id=hf_repo_id, filename=filename)\n",
    "\n",
    "\n",
    "m = load_quantized_model(\n",
    "        qmodel_path, \"cuda\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7607b1e8-2fa4-441e-9b7e-df4e20b8a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from deepcompressor.app.diffusion.pipeline.t5_encoder import text_encoder_2\n",
    "\n",
    "\n",
    "model = inject_transformer(model, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388aec8c-1467-487d-959d-d1da7ce0e2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "model.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a711a83-2f77-4825-9a2a-0eb2707f0abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder_2.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c58282e-7c99-43b8-b1b8-c6748d659b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc03a13c9ff4253ab3e429a176d22b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from diffusers import FluxControlNetModel\n",
    "from diffusers.pipelines import FluxControlNetPipeline\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# Load pipeline\n",
    "controlnet = FluxControlNetModel.from_pretrained(\n",
    "  \"jasperai/Flux.1-dev-Controlnet-Depth\",\n",
    "  torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "flux_id = \"black-forest-labs/FLUX.1-dev\"\n",
    "\n",
    "pipeline = FluxControlNetPipeline.from_pretrained(\n",
    "                flux_id,\n",
    "                transformer=model,\n",
    "                text_encoder_2=text_encoder_2,\n",
    "                torch_dtype=dtype,\n",
    "      controlnet=controlnet,\n",
    "\n",
    "            )\n",
    "pipeline.controlnet.to(\"cuda\")\n",
    "print(1)\n",
    "\n",
    "pipeline.vae.to(\"cuda\")\n",
    "pipeline.text_encoder.to(\"cuda\")\n",
    "\n",
    "print(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3b7a691-82b5-4f15-ae05-ab923e90efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afd166-f8d5-429b-b412-b443cccbdeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image\n",
    "\n",
    "\n",
    "control_image = load_image(\n",
    "  \"https://hf-mirror.com/jasperai/Flux.1-dev-Controlnet-Depth/resolve/main/examples/depth.jpg\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"a statue of a gnome in a field of purple tulips\"\n",
    "\n",
    "image = pipeline(\n",
    "    prompt, \n",
    "    control_image=control_image,\n",
    "    controlnet_conditioning_scale=0.6,\n",
    "    num_inference_steps=28, \n",
    "    guidance_scale=3.5,\n",
    "    height=control_image.size[1],\n",
    "    width=control_image.size[0]\n",
    ").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459251f6-c901-436d-ac90-6e90ce701665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
